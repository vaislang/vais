# Vais Self-Hosting Compiler - Lexer Module
# Tokenizer for Vais source code
# Imports token definitions from token module

U token

# ===== Lexer Helper Functions =====

# Check if character is digit (0-9: ASCII 48-57)
F is_digit(c: i64) -> i64 {
    I c >= 48 && c <= 57 { 1 } E { 0 }
}

# Check if character can start identifier (A-Z: 65-90, a-z: 97-122, _: 95)
F is_ident_start(c: i64) -> i64 {
    I (c >= 65 && c <= 90) || (c >= 97 && c <= 122) || c == 95 {
        1
    } E {
        0
    }
}

# Check if character can be part of identifier
F is_ident_char(c: i64) -> i64 {
    I is_ident_start(c) == 1 || is_digit(c) == 1 { 1 } E { 0 }
}

# Check if character is whitespace (space:32, tab:9, newline:10, carriage return:13)
F is_whitespace(c: i64) -> i64 {
    I c == 32 || c == 9 || c == 10 || c == 13 { 1 } E { 0 }
}

# Check if character is hex digit (0-9, A-F, a-f)
F is_hex_digit(c: i64) -> i64 {
    I is_digit(c) == 1 || (c >= 65 && c <= 70) || (c >= 97 && c <= 102) { 1 } E { 0 }
}

# Convert hex digit to value
F hex_digit_value(c: i64) -> i64 {
    I c >= 48 && c <= 57 {
        c - 48
    } E I c >= 65 && c <= 70 {
        c - 55
    } E I c >= 97 && c <= 102 {
        c - 87
    } E {
        0
    }
}

# ===== Lexer State =====

S Lexer {
    source: i64,     # Pointer to source string
    source_len: i64, # Length of source
    pos: i64,        # Current position
    line: i64,       # Current line number
    col: i64         # Current column number
}

X Lexer {
    # Create a new lexer for the given source code (pointer version)
    F new(source: i64, len: i64) -> Lexer = Lexer {
        source: source,
        source_len: len,
        pos: 0,
        line: 1,
        col: 1
    }

    # Check if at end of source
    F is_eof(&self) -> i64 {
        I self.pos >= self.source_len { 1 } E { 0 }
    }

    # Peek current character (returns 0 if at end)
    F peek(&self) -> i64 {
        I self.pos >= self.source_len {
            0
        } E {
            load_byte(self.source + self.pos)
        }
    }

    # Peek next character
    F peek_next(&self) -> i64 {
        I self.pos + 1 >= self.source_len {
            0
        } E {
            load_byte(self.source + self.pos + 1)
        }
    }

    # Advance to next character and return it
    F advance(&self) -> i64 {
        I self.pos < self.source_len {
            c := @.peek()
            I c == 10 {
                self.line = self.line + 1
                self.col = 1
                0
            } E {
                self.col = self.col + 1
                0
            }
            self.pos = self.pos + 1
            c
        } E {
            0
        }
    }

    # Skip a single-line comment (from # to end of line)
    F skip_comment(&self) -> i64 {
        L {
            I @.is_eof() == 1 { B }
            I @.peek() == 10 { B }
            @.advance()
        }
        0
    }

    # Check if current char is whitespace or comment start
    F is_skip_char(&self) -> i64 {
        I @.is_eof() == 1 { R 0 }
        c := @.peek()
        I is_whitespace(c) == 1 { R 1 }
        I c == 35 { R 1 }
        0
    }

    # Skip whitespace and comments
    F skip_whitespace(&self) -> i64 {
        L {
            I @.is_skip_char() == 0 { B }
            c := @.peek()
            I is_whitespace(c) == 1 {
                @.advance()
            } E {
                # Must be '#' (comment)
                @.skip_comment()
            }
        }
        1
    }

    # Scan a number literal (integer or float)
    F scan_number(&self) -> Token {
        start := self.pos
        value: mut i64 = 0
        is_float: mut i64 = 0

        # Check for hex literal (0x or 0X)
        I @.peek() == 48 && (@.peek_next() == 120 || @.peek_next() == 88) {
            @.advance()
            @.advance()
            L {
                I @.is_eof() == 1 { B }
                c := @.peek()
                I is_hex_digit(c) == 0 { B }
                value = value * 16 + hex_digit_value(c)
                @.advance()
            }
            R token_int_lit(value, start, self.pos)
        }

        # Regular decimal number
        L {
            I @.is_eof() == 1 { B }
            c := @.peek()
            I is_digit(c) == 0 { B }
            value = value * 10 + (c - 48)
            @.advance()
        }

        # Check for float (decimal point)
        I @.peek() == 46 && is_digit(@.peek_next()) == 1 {
            is_float = 1
            @.advance()
            L {
                I @.is_eof() == 1 { B }
                I is_digit(@.peek()) == 0 { B }
                @.advance()
            }
            0
        } E {
            0
        }

        # Check for exponent
        I @.peek() == 101 || @.peek() == 69 {
            is_float = 1
            @.advance()
            I @.peek() == 43 || @.peek() == 45 {
                @.advance()
                0
            } E {
                0
            }
            L {
                I @.is_eof() == 1 { B }
                I is_digit(@.peek()) == 0 { B }
                @.advance()
            }
            0
        } E {
            0
        }

        I is_float == 1 {
            token_float_lit(value, start, self.pos)
        } E {
            token_int_lit(value, start, self.pos)
        }
    }

    # Scan an identifier or keyword
    F scan_ident(&self) -> Token {
        start := self.pos
        str_start := self.source + self.pos

        L {
            I @.is_eof() == 1 { B }
            I is_ident_char(@.peek()) == 0 { B }
            @.advance()
        }

        len := self.pos - start

        # Check for single-letter keywords
        I len == 1 {
            c := load_byte(str_start)
            I c == 70 { R token_simple(TOK_KW_F(), start, self.pos) }
            I c == 83 { R token_simple(TOK_KW_S(), start, self.pos) }
            I c == 69 { R token_simple(TOK_KW_E(), start, self.pos) }
            I c == 73 { R token_simple(TOK_KW_I(), start, self.pos) }
            I c == 76 { R token_simple(TOK_KW_L(), start, self.pos) }
            I c == 77 { R token_simple(TOK_KW_M(), start, self.pos) }
            I c == 87 { R token_simple(TOK_KW_W(), start, self.pos) }
            I c == 88 { R token_simple(TOK_KW_X(), start, self.pos) }
            I c == 84 { R token_simple(TOK_KW_T(), start, self.pos) }
            I c == 85 { R token_simple(TOK_KW_U(), start, self.pos) }
            I c == 80 { R token_simple(TOK_KW_P(), start, self.pos) }
            I c == 65 { R token_simple(TOK_KW_A(), start, self.pos) }
            I c == 82 { R token_simple(TOK_KW_R(), start, self.pos) }
            I c == 66 { R token_simple(TOK_KW_B(), start, self.pos) }
            I c == 67 { R token_simple(TOK_KW_C(), start, self.pos) }
            I c == 68 { R token_simple(TOK_KW_D(), start, self.pos) }
            I c == 79 { R token_simple(TOK_KW_O(), start, self.pos) }
            I c == 78 { R token_simple(TOK_KW_N(), start, self.pos) }
            I c == 71 { R token_simple(TOK_KW_G(), start, self.pos) }
            I c == 89 { R token_simple(TOK_KW_Y(), start, self.pos) }
            0
        } E {
            0
        }

        # Check for type keywords (2-5 characters)
        I len == 2 {
            c0 := load_byte(str_start)
            c1 := load_byte(str_start + 1)
            I c0 == 105 && c1 == 56 { R token_simple(TOK_TY_I8(), start, self.pos) }
            I c0 == 117 && c1 == 56 { R token_simple(TOK_TY_U8(), start, self.pos) }
            0
        } E {
            0
        }

        I len == 3 {
            c0 := load_byte(str_start)
            c1 := load_byte(str_start + 1)
            c2 := load_byte(str_start + 2)
            I c0 == 105 && c1 == 54 && c2 == 52 { R token_simple(TOK_TY_I64(), start, self.pos) }
            I c0 == 105 && c1 == 51 && c2 == 50 { R token_simple(TOK_TY_I32(), start, self.pos) }
            I c0 == 105 && c1 == 49 && c2 == 54 { R token_simple(TOK_TY_I16(), start, self.pos) }
            I c0 == 117 && c1 == 54 && c2 == 52 { R token_simple(TOK_TY_U64(), start, self.pos) }
            I c0 == 117 && c1 == 51 && c2 == 50 { R token_simple(TOK_TY_U32(), start, self.pos) }
            I c0 == 117 && c1 == 49 && c2 == 54 { R token_simple(TOK_TY_U16(), start, self.pos) }
            I c0 == 102 && c1 == 54 && c2 == 52 { R token_simple(TOK_TY_F64(), start, self.pos) }
            I c0 == 102 && c1 == 51 && c2 == 50 { R token_simple(TOK_TY_F32(), start, self.pos) }
            I c0 == 115 && c1 == 116 && c2 == 114 { R token_simple(TOK_TY_STR(), start, self.pos) }
            I c0 == 109 && c1 == 117 && c2 == 116 { R token_simple(TOK_KW_MUT(), start, self.pos) }
            0
        } E {
            0
        }

        I len == 4 {
            c0 := load_byte(str_start)
            c1 := load_byte(str_start + 1)
            c2 := load_byte(str_start + 2)
            c3 := load_byte(str_start + 3)
            I c0 == 116 && c1 == 114 && c2 == 117 && c3 == 101 { R token_simple(TOK_KW_TRUE(), start, self.pos) }
            I c0 == 98 && c1 == 111 && c2 == 111 && c3 == 108 { R token_simple(TOK_TY_BOOL(), start, self.pos) }
            I c0 == 105 && c1 == 49 && c2 == 50 && c3 == 56 { R token_simple(TOK_TY_I128(), start, self.pos) }
            I c0 == 117 && c1 == 49 && c2 == 50 && c3 == 56 { R token_simple(TOK_TY_U128(), start, self.pos) }
            I c0 == 101 && c1 == 108 && c2 == 115 && c3 == 101 { R token_simple(TOK_KW_ELSE(), start, self.pos) }
            0
        } E {
            0
        }

        I len == 5 {
            c0 := load_byte(str_start)
            c1 := load_byte(str_start + 1)
            c2 := load_byte(str_start + 2)
            c3 := load_byte(str_start + 3)
            c4 := load_byte(str_start + 4)
            I c0 == 102 && c1 == 97 && c2 == 108 && c3 == 115 && c4 == 101 { R token_simple(TOK_KW_FALSE(), start, self.pos) }
            0
        } E {
            0
        }

        # Not a keyword, return as identifier
        token_string(TOK_IDENT(), str_start, len, start, self.pos)
    }

    # Scan a string literal
    F scan_string(&self) -> Token {
        start := self.pos
        @.advance()
        str_start := self.source + self.pos

        L {
            I @.is_eof() == 1 { B }
            c := @.peek()
            I c == 34 { B }
            I c == 92 {
                @.advance()
                I @.is_eof() == 0 {
                    @.advance()
                    0
                } E {
                    0
                }
            } E {
                @.advance()
                0
            }
        }

        len := self.source + self.pos - str_start

        I @.is_eof() == 0 && @.peek() == 34 {
            @.advance()
            0
        } E {
            0
        }

        token_string(TOK_STRING(), str_start, len, start, self.pos)
    }

    # Scan an operator or punctuation
    F scan_operator(&self) -> Token {
        start := self.pos
        c := @.advance()

        # Single-character tokens
        I c == 40 { R token_simple(TOK_LPAREN(), start, self.pos) }
        I c == 41 { R token_simple(TOK_RPAREN(), start, self.pos) }
        I c == 123 { R token_simple(TOK_LBRACE(), start, self.pos) }
        I c == 125 { R token_simple(TOK_RBRACE(), start, self.pos) }
        I c == 91 { R token_simple(TOK_LBRACKET(), start, self.pos) }
        I c == 93 { R token_simple(TOK_RBRACKET(), start, self.pos) }
        I c == 44 { R token_simple(TOK_COMMA(), start, self.pos) }
        I c == 59 { R token_simple(TOK_SEMI(), start, self.pos) }
        I c == 63 { R token_simple(TOK_QUESTION(), start, self.pos) }
        I c == 64 { R token_simple(TOK_AT(), start, self.pos) }
        I c == 126 { R token_simple(TOK_TILDE(), start, self.pos) }
        I c == 37 { R token_simple(TOK_PERCENT(), start, self.pos) }
        I c == 94 { R token_simple(TOK_CARET(), start, self.pos) }

        # Two-character operators
        I c == 43 {
            I @.peek() == 61 {
                @.advance()
                R token_simple(TOK_PLUS_EQ(), start, self.pos)
            }
            R token_simple(TOK_PLUS(), start, self.pos)
        }
        I c == 45 {
            I @.peek() == 62 {
                @.advance()
                R token_simple(TOK_ARROW(), start, self.pos)
            }
            I @.peek() == 61 {
                @.advance()
                R token_simple(TOK_MINUS_EQ(), start, self.pos)
            }
            R token_simple(TOK_MINUS(), start, self.pos)
        }
        I c == 42 {
            I @.peek() == 61 {
                @.advance()
                R token_simple(TOK_STAR_EQ(), start, self.pos)
            }
            R token_simple(TOK_STAR(), start, self.pos)
        }
        I c == 47 {
            I @.peek() == 61 {
                @.advance()
                R token_simple(TOK_SLASH_EQ(), start, self.pos)
            }
            R token_simple(TOK_SLASH(), start, self.pos)
        }
        I c == 60 {
            I @.peek() == 61 {
                @.advance()
                R token_simple(TOK_LT_EQ(), start, self.pos)
            }
            I @.peek() == 60 {
                @.advance()
                R token_simple(TOK_SHL(), start, self.pos)
            }
            R token_simple(TOK_LT(), start, self.pos)
        }
        I c == 62 {
            I @.peek() == 61 {
                @.advance()
                R token_simple(TOK_GT_EQ(), start, self.pos)
            }
            I @.peek() == 62 {
                @.advance()
                R token_simple(TOK_SHR(), start, self.pos)
            }
            R token_simple(TOK_GT(), start, self.pos)
        }
        I c == 61 {
            I @.peek() == 61 {
                @.advance()
                R token_simple(TOK_EQ_EQ(), start, self.pos)
            }
            I @.peek() == 62 {
                @.advance()
                R token_simple(TOK_FAT_ARROW(), start, self.pos)
            }
            R token_simple(TOK_EQ(), start, self.pos)
        }
        I c == 33 {
            I @.peek() == 61 {
                @.advance()
                R token_simple(TOK_NOT_EQ(), start, self.pos)
            }
            R token_simple(TOK_BANG(), start, self.pos)
        }
        I c == 38 {
            I @.peek() == 38 {
                @.advance()
                R token_simple(TOK_AND(), start, self.pos)
            }
            R token_simple(TOK_AMP(), start, self.pos)
        }
        I c == 124 {
            I @.peek() == 124 {
                @.advance()
                R token_simple(TOK_OR(), start, self.pos)
            }
            R token_simple(TOK_PIPE(), start, self.pos)
        }
        I c == 58 {
            I @.peek() == 61 {
                @.advance()
                R token_simple(TOK_COLON_EQ(), start, self.pos)
            }
            I @.peek() == 58 {
                @.advance()
                R token_simple(TOK_COLON_COLON(), start, self.pos)
            }
            R token_simple(TOK_COLON(), start, self.pos)
        }
        I c == 46 {
            I @.peek() == 46 {
                @.advance()
                I @.peek() == 61 {
                    @.advance()
                    R token_simple(TOK_DOT_DOT_EQ(), start, self.pos)
                }
                R token_simple(TOK_DOT_DOT(), start, self.pos)
            }
            R token_simple(TOK_DOT(), start, self.pos)
        }

        token_simple(TOK_ERROR(), start, self.pos)
    }

    # Get the next token
    F next_token(&self) -> Token {
        @.skip_whitespace()

        I @.is_eof() == 1 {
            R token_simple(TOK_EOF(), self.pos, self.pos)
        }

        c := @.peek()

        I is_digit(c) == 1 {
            R @.scan_number()
        }

        I is_ident_start(c) == 1 {
            R @.scan_ident()
        }

        I c == 34 {
            R @.scan_string()
        }

        @.scan_operator()
    }

    # Tokenize the entire source and return a TokenList
    F tokenize(&self) -> TokenList {
        tokens := tokenlist_new(256)

        L {
            tok := @.next_token()
            tokens.push_fields(tok.kind, tok.value, tok.str_ptr, tok.str_len, tok.span_start, tok.span_end)
            I tok.kind == TOK_EOF() { B }
        }

        tokens
    }
}

# Test function (renamed from main to allow module import)
F test_lexer_main() -> i64 {
    puts("Lexer test")
    0
}
