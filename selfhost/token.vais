# Vais Self-Hosting Compiler - Token Module
# Token definitions for the lexer

# Note: imports not needed for this standalone module

# Token type constants (using i64 since Vais enum support is limited)
# We use integer constants to represent token types

# Keyword tokens (1-30)
F TOK_KW_F() -> i64 = 1        # function
F TOK_KW_S() -> i64 = 2        # struct
F TOK_KW_E() -> i64 = 3        # enum
F TOK_KW_I() -> i64 = 4        # if
F TOK_KW_L() -> i64 = 5        # loop
F TOK_KW_M() -> i64 = 6        # match
F TOK_KW_W() -> i64 = 7        # trait (With)
F TOK_KW_X() -> i64 = 8        # impl (eXtend)
F TOK_KW_T() -> i64 = 9        # type
F TOK_KW_U() -> i64 = 10       # use
F TOK_KW_P() -> i64 = 11       # pub
F TOK_KW_A() -> i64 = 12       # async
F TOK_KW_R() -> i64 = 13       # return
F TOK_KW_B() -> i64 = 14       # break
F TOK_KW_C() -> i64 = 15       # continue
F TOK_KW_TRUE() -> i64 = 16
F TOK_KW_FALSE() -> i64 = 17
F TOK_KW_MUT() -> i64 = 18
F TOK_KW_ELSE() -> i64 = 19
F TOK_KW_D() -> i64 = 20       # defer
F TOK_KW_O() -> i64 = 21       # union
F TOK_KW_N() -> i64 = 22       # extern
F TOK_KW_G() -> i64 = 23       # global
F TOK_KW_Y() -> i64 = 24       # await
F TOK_KW_SELF() -> i64 = 25    # self
F TOK_KW_SELF_UPPER() -> i64 = 26 # Self
F TOK_KW_AS() -> i64 = 27      # as
F TOK_KW_CONST() -> i64 = 28   # const
F TOK_KW_SPAWN() -> i64 = 29   # spawn
F TOK_KW_MACRO() -> i64 = 30   # macro

# Additional keywords (121-140)
F TOK_KW_COMPTIME() -> i64 = 121  # comptime
F TOK_KW_DYN() -> i64 = 122       # dyn
F TOK_KW_LINEAR() -> i64 = 123    # linear
F TOK_KW_AFFINE() -> i64 = 124    # affine
F TOK_KW_MOVE() -> i64 = 125      # move
F TOK_KW_CONSUME() -> i64 = 126   # consume
F TOK_KW_LAZY() -> i64 = 127      # lazy
F TOK_KW_FORCE() -> i64 = 128     # force

# Type keyword tokens (31-50)
F TOK_TY_I8() -> i64 = 31
F TOK_TY_I16() -> i64 = 32
F TOK_TY_I32() -> i64 = 33
F TOK_TY_I64() -> i64 = 34
F TOK_TY_I128() -> i64 = 35
F TOK_TY_U8() -> i64 = 36
F TOK_TY_U16() -> i64 = 37
F TOK_TY_U32() -> i64 = 38
F TOK_TY_U64() -> i64 = 39
F TOK_TY_U128() -> i64 = 40
F TOK_TY_F32() -> i64 = 41
F TOK_TY_F64() -> i64 = 42
F TOK_TY_BOOL() -> i64 = 43
F TOK_TY_STR() -> i64 = 44

# SIMD vector types (45-50)
F TOK_TY_VEC2F32() -> i64 = 45
F TOK_TY_VEC4F32() -> i64 = 46
F TOK_TY_VEC8F32() -> i64 = 47
F TOK_TY_VEC2F64() -> i64 = 48
F TOK_TY_VEC4F64() -> i64 = 49
F TOK_TY_VEC4I32() -> i64 = 50
F TOK_TY_VEC8I32() -> i64 = 141
F TOK_TY_VEC2I64() -> i64 = 142
F TOK_TY_VEC4I64() -> i64 = 143

# Literal tokens (51-60)
F TOK_INT() -> i64 = 51        # Integer literal
F TOK_FLOAT() -> i64 = 52      # Float literal
F TOK_STRING() -> i64 = 53     # String literal
F TOK_IDENT() -> i64 = 54      # Identifier

# Operator tokens (61-100)
F TOK_PLUS() -> i64 = 61       # +
F TOK_MINUS() -> i64 = 62      # -
F TOK_STAR() -> i64 = 63       # *
F TOK_SLASH() -> i64 = 64      # /
F TOK_PERCENT() -> i64 = 65    # %
F TOK_LT() -> i64 = 66         # <
F TOK_GT() -> i64 = 67         # >
F TOK_LT_EQ() -> i64 = 68      # <=
F TOK_GT_EQ() -> i64 = 69      # >=
F TOK_EQ_EQ() -> i64 = 70      # ==
F TOK_NOT_EQ() -> i64 = 71     # !=
F TOK_AMP() -> i64 = 72        # &
F TOK_PIPE() -> i64 = 73       # |
F TOK_CARET() -> i64 = 74      # ^
F TOK_TILDE() -> i64 = 75      # ~
F TOK_SHL() -> i64 = 76        # <<
F TOK_SHR() -> i64 = 77        # >>
F TOK_BANG() -> i64 = 78       # !
F TOK_AND() -> i64 = 79        # &&
F TOK_OR() -> i64 = 80         # ||

# Assignment tokens (81-90)
F TOK_EQ() -> i64 = 81         # =
F TOK_COLON_EQ() -> i64 = 82   # :=
F TOK_PLUS_EQ() -> i64 = 83    # +=
F TOK_MINUS_EQ() -> i64 = 84   # -=
F TOK_STAR_EQ() -> i64 = 85    # *=
F TOK_SLASH_EQ() -> i64 = 86   # /=

# Delimiter tokens (91-100)
F TOK_LPAREN() -> i64 = 91     # (
F TOK_RPAREN() -> i64 = 92     # )
F TOK_LBRACE() -> i64 = 93     # {
F TOK_RBRACE() -> i64 = 94     # }
F TOK_LBRACKET() -> i64 = 95   # [
F TOK_RBRACKET() -> i64 = 96   # ]

# Punctuation tokens (101-120)
F TOK_COMMA() -> i64 = 101     # ,
F TOK_COLON() -> i64 = 102     # :
F TOK_SEMI() -> i64 = 103      # ;
F TOK_DOT() -> i64 = 104       # .
F TOK_DOT_DOT() -> i64 = 105   # ..
F TOK_DOT_DOT_EQ() -> i64 = 106 # ..=
F TOK_ARROW() -> i64 = 107     # ->
F TOK_FAT_ARROW() -> i64 = 108 # =>
F TOK_COLON_COLON() -> i64 = 109 # ::
F TOK_QUESTION() -> i64 = 110  # ?
F TOK_AT() -> i64 = 111        # @
F TOK_HASH() -> i64 = 112      # #
F TOK_PIPE_ARROW() -> i64 = 113  # |>
F TOK_ELLIPSIS() -> i64 = 114    # ...
F TOK_DOLLAR() -> i64 = 115      # $
F TOK_HASH_BRACKET() -> i64 = 116 # #[
F TOK_LIFETIME() -> i64 = 117    # 'a, 'static, etc.

# Special tokens
F TOK_EOF() -> i64 = 200
F TOK_ERROR() -> i64 = 201

# Token structure - stores token type and associated data
# Note: All values stored as i64 for simplicity (float bits stored as i64)
S Token {
    kind: i64,           # Token type constant
    value: i64,          # For integer/float literals (float stored as bits)
    str_ptr: i64,        # Pointer to string data (for strings/idents)
    str_len: i64,        # Length of string data
    span_start: i64,     # Source start position
    span_end: i64        # Source end position
}

X Token {
    # Create a simple token (no value)
    F simple(kind: i64, start: i64, end: i64) -> Token = Token {
        kind: kind,
        value: 0,
        str_ptr: 0,
        str_len: 0,
        span_start: start,
        span_end: end
    }

    # Create an integer literal token
    F int_lit(val: i64, start: i64, end: i64) -> Token = Token {
        kind: TOK_INT(),
        value: val,
        str_ptr: 0,
        str_len: 0,
        span_start: start,
        span_end: end
    }

    # Create a float literal token (value stored as bit pattern)
    F float_lit(val: i64, start: i64, end: i64) -> Token = Token {
        kind: TOK_FLOAT(),
        value: val,
        str_ptr: 0,
        str_len: 0,
        span_start: start,
        span_end: end
    }

    # Create a string/identifier token
    F string_token(kind: i64, ptr: i64, len: i64, start: i64, end: i64) -> Token = Token {
        kind: kind,
        value: 0,
        str_ptr: ptr,
        str_len: len,
        span_start: start,
        span_end: end
    }

    # Check if token is a keyword
    F is_keyword(&self) -> i64 {
        I self.kind >= 1 && self.kind <= 30 { 1 } E { 0 }
    }

    # Check if token is a type keyword
    F is_type_keyword(&self) -> i64 {
        I self.kind >= 31 && self.kind <= 50 { 1 } E { 0 }
    }

    # Check if token is a literal
    F is_literal(&self) -> i64 {
        I self.kind >= 51 && self.kind <= 60 { 1 } E { 0 }
    }

    # Check if token is an operator
    F is_operator(&self) -> i64 {
        I self.kind >= 61 && self.kind <= 80 { 1 } E { 0 }
    }

    # Check if token is EOF
    F is_eof(&self) -> i64 {
        I self.kind == TOK_EOF() { 1 } E { 0 }
    }

    # Get operator precedence (higher = tighter binding)
    F precedence(&self) -> i64 {
        k := self.kind
        I k == 80 { 1 }                                          # ||
        E I k == 79 { 2 }                                        # &&
        E I k == 73 { 3 }                                        # |
        E I k == 74 { 4 }                                        # ^
        E I k == 72 { 5 }                                        # &
        E I k == 70 || k == 71 { 6 }                             # == !=
        E I k == 66 || k == 67 || k == 68 || k == 69 { 7 }       # < > <= >=
        E I k == 76 || k == 77 { 8 }                             # << >>
        E I k == 61 || k == 62 { 9 }                             # + -
        E I k == 63 || k == 64 || k == 65 { 10 }                 # * / %
        E { 0 }
    }
}

# Token list for lexer output
S TokenList {
    data: i64,    # Pointer to Token array
    len: i64,     # Current number of tokens
    cap: i64      # Capacity
}

X TokenList {
    # Create a new token list
    F new(capacity: i64) -> TokenList {
        data := malloc(capacity * 48)  # Each Token is ~64 bytes
        TokenList { data: data, len: 0, cap: capacity }
    }

    # Add a token to the list (pass fields directly to avoid struct parameter bug)
    F push_fields(&self, kind: i64, value: i64, str_ptr: i64, str_len: i64, span_start: i64, span_end: i64) -> i64 {
        I self.len >= self.cap {
            # Grow the list
            @.grow()
        }
        # Store token at current position
        ptr := self.data + self.len * 48
        store_token_fields(ptr, kind, value, str_ptr, str_len, span_start, span_end)
        self.len = self.len + 1
        self.len
    }

    # Get token at index - uses unsafe access (caller must ensure valid index)
    F get(&self, index: i64) -> Token {
        ptr := self.data + index * 48
        Token {
            kind: load_i64(ptr + 0),
            value: load_i64(ptr + 8),
            str_ptr: load_i64(ptr + 16),
            str_len: load_i64(ptr + 24),
            span_start: load_i64(ptr + 32),
            span_end: load_i64(ptr + 40)
        }
    }

    # Check if index is valid
    F is_valid_index(&self, index: i64) -> i64 {
        I index >= 0 && index < self.len { 1 } E { 0 }
    }

    # Grow the list
    F grow(&self) -> i64 {
        new_cap := self.cap * 2
        new_data := malloc(new_cap * 48)
        memcpy(new_data, self.data, self.len * 48)
        free(self.data)
        self.data = new_data
        self.cap = new_cap
        1
    }

    # Get length
    F len(&self) -> i64 = self.len

    # Free the list
    F drop(&self) -> i64 {
        free(self.data)
        1
    }
}

# Global helper functions for token creation (used by lexer)
F token_simple(kind: i64, start: i64, end: i64) -> Token = Token {
    kind: kind,
    value: 0,
    str_ptr: 0,
    str_len: 0,
    span_start: start,
    span_end: end
}

F token_int_lit(val: i64, start: i64, end: i64) -> Token = Token {
    kind: TOK_INT(),
    value: val,
    str_ptr: 0,
    str_len: 0,
    span_start: start,
    span_end: end
}

F token_float_lit(val: i64, start: i64, end: i64) -> Token = Token {
    kind: TOK_FLOAT(),
    value: val,
    str_ptr: 0,
    str_len: 0,
    span_start: start,
    span_end: end
}

F token_string(kind: i64, ptr: i64, len: i64, start: i64, end: i64) -> Token = Token {
    kind: kind,
    value: 0,
    str_ptr: ptr,
    str_len: len,
    span_start: start,
    span_end: end
}

F tokenlist_new(capacity: i64) -> TokenList {
    data := malloc(capacity * 48)
    TokenList { data: data, len: 0, cap: capacity }
}

# Helper functions for token storage (using memory primitives)
# Token size: 6 fields * 8 bytes = 48 bytes
# store_token_fields: store token fields individually to dst pointer
F store_token_fields(dst: i64, kind: i64, value: i64, str_ptr: i64, str_len: i64, span_start: i64, span_end: i64) -> i64 {
    store_i64(dst + 0, kind)
    store_i64(dst + 8, value)
    store_i64(dst + 16, str_ptr)
    store_i64(dst + 24, str_len)
    store_i64(dst + 32, span_start)
    store_i64(dst + 40, span_end)
    1
}

# Test function (renamed from main to allow module import)
F test_token_main() -> i64 {
    puts("Token module loaded")

    # Test token creation
    tok := Token.simple(TOK_KW_F(), 0, 1)
    I tok.kind == 1 {
        puts("Token creation: OK")
        0
    } E {
        puts("Token creation: FAIL")
        0
    }

    # Test TokenList
    list := TokenList.new(16)
    list.push_fields(tok.kind, tok.value, tok.str_ptr, tok.str_len, tok.span_start, tok.span_end)
    I list.len() == 1 {
        puts("TokenList: OK")
        0
    } E {
        puts("TokenList: FAIL")
        0
    }

    list.drop()
    puts("All tests passed!")
    0
}
