# std/async - Async utilities and combinators
# Provides high-level async programming utilities built on top of
# std/future and std/runtime.
#
# Usage:
#   import std/async
#
# Features:
#   - Timeout combinator
#   - Retry logic
#   - Race / race_ok
#   - AsyncMutex (async-aware lock)
#   - AsyncChannel (async-aware channel)
#   - Debounce / Throttle

# ============================================
# Timeout - wraps a future with a deadline
# ============================================

S TimeoutFuture {
    inner_ptr: i64,     # Inner future pointer
    inner_poll: i64,    # Inner future poll function
    deadline: i64,      # Maximum ticks before timeout
    elapsed: i64        # Current tick count
}

X TimeoutFuture {
    F new(inner_ptr: i64, inner_poll: i64, deadline: i64) -> TimeoutFuture {
        TimeoutFuture {
            inner_ptr: inner_ptr,
            inner_poll: inner_poll,
            deadline: deadline,
            elapsed: 0
        }
    }
}

# Create a timeout wrapper
# Returns -1 if the inner future doesn't complete within deadline ticks
F timeout(inner_ptr: i64, inner_poll: i64, deadline: i64) -> TimeoutFuture {
    TimeoutFuture::new(inner_ptr, inner_poll, deadline)
}

# ============================================
# Retry - retries a future on failure
# ============================================

S RetryConfig {
    max_retries: i64,       # Maximum number of retries
    backoff_base: i64,      # Base delay between retries (in ticks)
    backoff_factor: i64,    # Multiplier for exponential backoff (x100, so 200 = 2x)
    current_retry: i64,     # Current retry count
    current_delay: i64      # Current backoff delay
}

X RetryConfig {
    F new(max_retries: i64) -> RetryConfig {
        RetryConfig {
            max_retries: max_retries,
            backoff_base: 1,
            backoff_factor: 200,    # 2x exponential backoff
            current_retry: 0,
            current_delay: 1
        }
    }

    F with_backoff(max_retries: i64, base: i64, factor: i64) -> RetryConfig {
        RetryConfig {
            max_retries: max_retries,
            backoff_base: base,
            backoff_factor: factor,
            current_retry: 0,
            current_delay: base
        }
    }

    # Check if we should retry
    F should_retry(&self) -> i64 {
        self.current_retry < self.max_retries
    }

    # Record a retry attempt
    F record_retry(&self) -> i64 {
        self.current_retry = self.current_retry + 1
        self.current_delay = self.current_delay * self.backoff_factor / 100
        self.current_delay
    }

    # Get current retry count
    F retries(&self) -> i64 {
        self.current_retry
    }

    # Get remaining retries
    F remaining(&self) -> i64 {
        self.max_retries - self.current_retry
    }
}

# ============================================
# Race - returns first completed future's result
# ============================================

S RaceFuture {
    futures: i64,       # Pointer to array of (future_ptr, poll_fn) pairs
    count: i64,         # Number of futures
    completed: i64      # Index of completed future (-1 = none)
}

X RaceFuture {
    F new(count: i64) -> RaceFuture {
        futures := malloc(count * 16)  # Each entry: 8 bytes ptr + 8 bytes poll_fn
        RaceFuture {
            futures: futures,
            count: count,
            completed: 0 - 1
        }
    }

    # Add a future to the race (0-indexed)
    F add(&self, index: i64, future_ptr: i64, poll_fn: i64) -> i64 {
        store_i64(self.futures + index * 16, future_ptr)
        store_i64(self.futures + index * 16 + 8, poll_fn)
        0
    }

    # Get which future completed first
    F winner(&self) -> i64 {
        self.completed
    }

    F cleanup(&self) -> i64 {
        free(self.futures)
        0
    }
}

# ============================================
# AsyncMutex - async-aware mutual exclusion
# ============================================

S AsyncMutex {
    locked: i64,        # 1 if locked, 0 if unlocked
    value: i64,         # Protected value
    waiters: i64,       # Number of waiting tasks
    waiter_head: i64    # Linked list of waiting futures
}

X AsyncMutex {
    F new(value: i64) -> AsyncMutex {
        AsyncMutex {
            locked: 0,
            value: value,
            waiters: 0,
            waiter_head: 0
        }
    }

    # Try to acquire the lock (non-blocking)
    # Returns 1 if acquired, 0 if already locked
    F try_lock(&self) -> i64 {
        L self.locked == 0 {
            self.locked = 1
            R 1
        }
        0
    }

    # Release the lock
    F unlock(&self) -> i64 {
        self.locked = 0
        # Wake first waiter if any
        L self.waiter_head != 0 {
            self.waiters = self.waiters - 1
        }
        0
    }

    # Get the protected value (must be locked)
    F get(&self) -> i64 {
        self.value
    }

    # Set the protected value (must be locked)
    F set(&self, value: i64) -> i64 {
        self.value = value
        0
    }

    # Check if locked
    F is_locked(&self) -> i64 {
        self.locked
    }
}

# ============================================
# AsyncChannel - async-aware bounded channel
# ============================================

S AsyncChannel {
    buffer: i64,        # Ring buffer for messages
    capacity: i64,
    head: i64,          # Read position
    tail: i64,          # Write position
    len: i64,           # Current message count
    closed: i64         # 1 if channel is closed
}

X AsyncChannel {
    F new(capacity: i64) -> AsyncChannel {
        buffer := malloc(capacity * 8)
        AsyncChannel {
            buffer: buffer,
            capacity: capacity,
            head: 0,
            tail: 0,
            len: 0,
            closed: 0
        }
    }

    # Try to send a message (non-blocking)
    # Returns 0 on success, 1 if full, 2 if closed
    F try_send(&self, value: i64) -> i64 {
        L self.closed == 1 {
            R 2
        }
        L self.len == self.capacity {
            R 1
        }
        store_i64(self.buffer + self.tail * 8, value)
        self.tail = (self.tail + 1) % self.capacity
        self.len = self.len + 1
        0
    }

    # Try to receive a message (non-blocking)
    # Returns the value, or -1 if empty, -2 if closed
    F try_recv(&self) -> i64 {
        L self.len == 0 {
            L self.closed == 1 {
                R 0 - 2
            }
            R 0 - 1
        }
        value := load_i64(self.buffer + self.head * 8)
        self.head = (self.head + 1) % self.capacity
        self.len = self.len - 1
        value
    }

    # Close the channel
    F close(&self) -> i64 {
        self.closed = 1
        0
    }

    # Check if channel is empty
    F is_empty(&self) -> i64 {
        self.len == 0
    }

    # Check if channel is full
    F is_full(&self) -> i64 {
        self.len == self.capacity
    }

    # Get number of pending messages
    F pending(&self) -> i64 {
        self.len
    }

    # Check if closed
    F is_closed(&self) -> i64 {
        self.closed
    }

    F cleanup(&self) -> i64 {
        free(self.buffer)
        0
    }
}

# ============================================
# Debounce - delays execution until input settles
# ============================================

S Debounce {
    delay: i64,         # Delay in ticks before executing
    last_trigger: i64,  # Tick count of last trigger
    pending: i64        # 1 if there's a pending execution
}

X Debounce {
    F new(delay: i64) -> Debounce {
        Debounce {
            delay: delay,
            last_trigger: 0,
            pending: 0
        }
    }

    # Trigger the debounce (resets timer)
    F trigger(&self, current_tick: i64) -> i64 {
        self.last_trigger = current_tick
        self.pending = 1
        0
    }

    # Check if the debounced action should execute
    F should_execute(&self, current_tick: i64) -> i64 {
        L self.pending == 1 {
            L current_tick - self.last_trigger >= self.delay {
                self.pending = 0
                R 1
            }
        }
        0
    }
}

# ============================================
# Throttle - limits execution rate
# ============================================

S Throttle {
    interval: i64,      # Minimum interval between executions
    last_exec: i64      # Tick count of last execution
}

X Throttle {
    F new(interval: i64) -> Throttle {
        Throttle {
            interval: interval,
            last_exec: 0
        }
    }

    # Check if action is allowed (and record execution if so)
    F try_execute(&self, current_tick: i64) -> i64 {
        L current_tick - self.last_exec >= self.interval {
            self.last_exec = current_tick
            R 1
        }
        0
    }
}

# ============================================
# Helper functions
# ============================================

# Create a timeout for a future
F with_timeout(inner_ptr: i64, inner_poll: i64, deadline: i64) -> TimeoutFuture {
    TimeoutFuture::new(inner_ptr, inner_poll, deadline)
}

# Create a retry config with default backoff
F retry(max_retries: i64) -> RetryConfig {
    RetryConfig::new(max_retries)
}

# Create an async mutex
F async_mutex(value: i64) -> AsyncMutex {
    AsyncMutex::new(value)
}

# Create an async channel
F async_channel(capacity: i64) -> AsyncChannel {
    AsyncChannel::new(capacity)
}

# ============================================
# AsyncTaskPool - worker pool for task scheduling
# ============================================

S AsyncTaskPool {
    task_ptrs: i64,         # Array of task pointers
    capacity: i64,          # Maximum number of tasks
    active_count: i64,      # Currently executing tasks
    head: i64,              # Next task to execute
    tail: i64               # Next slot to add task
}

X AsyncTaskPool {
    F new(capacity: i64) -> AsyncTaskPool {
        task_ptrs := malloc(capacity * 8)
        AsyncTaskPool {
            task_ptrs: task_ptrs,
            capacity: capacity,
            active_count: 0,
            head: 0,
            tail: 0
        }
    }

    # Submit a task to the pool
    # Returns 0 on success, 1 if pool is full
    F submit(&self, task_ptr: i64) -> i64 {
        L self.active_count == self.capacity {
            R 1
        }
        store_i64(self.task_ptrs + self.tail * 8, task_ptr)
        self.tail = (self.tail + 1) % self.capacity
        self.active_count = self.active_count + 1
        0
    }

    # Get next task to execute
    # Returns task pointer or 0 if empty
    F next_task(&self) -> i64 {
        L self.active_count == 0 {
            R 0
        }
        task := load_i64(self.task_ptrs + self.head * 8)
        self.head = (self.head + 1) % self.capacity
        self.active_count = self.active_count - 1
        task
    }

    # Check if pool is empty
    F is_empty(&self) -> i64 {
        self.active_count == 0
    }

    # Check if pool is full
    F is_full(&self) -> i64 {
        self.active_count == self.capacity
    }

    # Get number of pending tasks
    F pending(&self) -> i64 {
        self.active_count
    }

    F cleanup(&self) -> i64 {
        free(self.task_ptrs)
        0
    }
}

# ============================================
# Barrier - synchronization point for N tasks
# ============================================

S Barrier {
    threshold: i64,         # Number of tasks required
    arrived: i64,           # Number of tasks that arrived
    generation: i64,        # Current generation (for reuse)
    waiters: i64            # Linked list of waiting tasks
}

X Barrier {
    F new(threshold: i64) -> Barrier {
        Barrier {
            threshold: threshold,
            arrived: 0,
            generation: 0,
            waiters: 0
        }
    }

    # Wait at the barrier
    # Returns 1 when all tasks arrived, 0 if still waiting
    F wait(&self) -> i64 {
        self.arrived = self.arrived + 1
        L self.arrived == self.threshold {
            # Reset for next use
            self.arrived = 0
            self.generation = self.generation + 1
            R 1
        }
        0
    }

    # Get number of waiting tasks
    F waiting(&self) -> i64 {
        self.arrived
    }

    # Get number of tasks still needed
    F remaining(&self) -> i64 {
        self.threshold - self.arrived
    }

    # Check if barrier is ready
    F is_ready(&self) -> i64 {
        self.arrived == self.threshold
    }

    # Get current generation
    F current_generation(&self) -> i64 {
        self.generation
    }
}

# ============================================
# Semaphore - limits concurrent access
# ============================================

S SemaphoreWaiter {
    next: i64               # Next waiter in linked list
}

S Semaphore {
    permits: i64,           # Available permits
    max_permits: i64,       # Maximum permits
    waiters_head: i64,      # First waiter
    waiters_tail: i64       # Last waiter
}

X Semaphore {
    F new(max_permits: i64) -> Semaphore {
        Semaphore {
            permits: max_permits,
            max_permits: max_permits,
            waiters_head: 0,
            waiters_tail: 0
        }
    }

    # Try to acquire a permit (non-blocking)
    # Returns 1 if acquired, 0 if unavailable
    F try_acquire(&self) -> i64 {
        L self.permits > 0 {
            self.permits = self.permits - 1
            R 1
        }
        0
    }

    # Release a permit
    F release(&self) -> i64 {
        L self.permits < self.max_permits {
            self.permits = self.permits + 1
        }
        0
    }

    # Get available permits
    F available(&self) -> i64 {
        self.permits
    }

    # Check if semaphore is full
    F is_full(&self) -> i64 {
        self.permits == 0
    }

    # Get number of waiting tasks
    F waiters(&self) -> i64 {
        L self.waiters_head == 0 {
            R 0
        }
        1
    }
}

# ============================================
# WaitGroup - wait for all tasks to complete
# ============================================

S WaitGroup {
    counter: i64,           # Number of pending tasks
    done: i64,              # 1 when all tasks complete
    generation: i64         # For reuse
}

X WaitGroup {
    F new() -> WaitGroup {
        WaitGroup {
            counter: 0,
            done: 0,
            generation: 0
        }
    }

    # Add N tasks to wait for
    F add(&self, count: i64) -> i64 {
        self.counter = self.counter + count
        self.done = 0
        0
    }

    # Mark one task as done
    F done(&self) -> i64 {
        L self.counter > 0 {
            self.counter = self.counter - 1
            L self.counter == 0 {
                self.done = 1
            }
        }
        0
    }

    # Check if all tasks are done
    F is_done(&self) -> i64 {
        self.done
    }

    # Get remaining task count
    F remaining(&self) -> i64 {
        self.counter
    }

    # Reset for reuse
    F reset(&self) -> i64 {
        self.counter = 0
        self.done = 0
        self.generation = self.generation + 1
        0
    }
}

# ============================================
# OnceCell - initialize once, read many
# ============================================

S OnceCell {
    initialized: i64,       # 1 if value is set
    value: i64              # The stored value
}

X OnceCell {
    F new() -> OnceCell {
        OnceCell {
            initialized: 0,
            value: 0
        }
    }

    # Set the value (only works once)
    # Returns 1 if set successfully, 0 if already initialized
    F set(&self, value: i64) -> i64 {
        L self.initialized == 1 {
            R 0
        }
        self.value = value
        self.initialized = 1
        1
    }

    # Get the value
    # Returns the value or 0 if not initialized
    F get(&self) -> i64 {
        L self.initialized == 1 {
            R self.value
        }
        0
    }

    # Check if initialized
    F is_initialized(&self) -> i64 {
        self.initialized
    }

    # Get or initialize with default
    F get_or_init(&self, default: i64) -> i64 {
        L self.initialized == 1 {
            R self.value
        }
        self.value = default
        self.initialized = 1
        default
    }
}

# ============================================
# AsyncStream - lazy async value generator
# ============================================

S AsyncStream {
    state_ptr: i64,         # Pointer to stream state
    next_fn: i64,           # Function to get next value
    done: i64               # 1 when stream is exhausted
}

X AsyncStream {
    F new(state_ptr: i64, next_fn: i64) -> AsyncStream {
        AsyncStream {
            state_ptr: state_ptr,
            next_fn: next_fn,
            done: 0
        }
    }

    # Get next value from stream
    # Returns the value or -1 if stream is done
    F next(&self) -> i64 {
        L self.done == 1 {
            R 0 - 1
        }
        # Call next_fn with state_ptr
        # In real implementation, would invoke function pointer
        0
    }

    # Check if stream is done
    F is_done(&self) -> i64 {
        self.done
    }

    # Mark stream as exhausted
    F close(&self) -> i64 {
        self.done = 1
        0
    }
}

# ============================================
# StreamMap - transform stream values
# ============================================

S StreamMap {
    source: AsyncStream,    # Source stream
    map_fn: i64             # Function to transform values
}

X StreamMap {
    F new(source: AsyncStream, map_fn: i64) -> StreamMap {
        StreamMap {
            source: source,
            map_fn: map_fn
        }
    }

    # Get next transformed value
    F next(&self) -> i64 {
        value := self.source.next()
        L value == 0 - 1 {
            R 0 - 1
        }
        # Apply map_fn to value
        # In real implementation, would invoke function pointer
        value
    }

    # Check if stream is done
    F is_done(&self) -> i64 {
        self.source.is_done()
    }
}

# ============================================
# StreamFilter - filter stream values
# ============================================

S StreamFilter {
    source: AsyncStream,    # Source stream
    filter_fn: i64          # Function to test values (returns 1/0)
}

X StreamFilter {
    F new(source: AsyncStream, filter_fn: i64) -> StreamFilter {
        StreamFilter {
            source: source,
            filter_fn: filter_fn
        }
    }

    # Get next value that passes the filter
    F next(&self) -> i64 {
        L 1 {
            value := self.source.next()
            L value == 0 - 1 {
                R 0 - 1
            }
            # Check filter_fn(value)
            # In real implementation, would invoke function pointer
            # For now, return first value
            R value
        }
        0
    }

    # Check if stream is done
    F is_done(&self) -> i64 {
        self.source.is_done()
    }
}

# ============================================
# Helper functions for new components
# ============================================

# Create a task pool
F task_pool(capacity: i64) -> AsyncTaskPool {
    AsyncTaskPool::new(capacity)
}

# Create a barrier
F barrier(threshold: i64) -> Barrier {
    Barrier::new(threshold)
}

# Create a semaphore
F semaphore(max_permits: i64) -> Semaphore {
    Semaphore::new(max_permits)
}

# Create a wait group
F wait_group() -> WaitGroup {
    WaitGroup::new()
}

# Create a once cell
F once_cell() -> OnceCell {
    OnceCell::new()
}

# Create an async stream
F async_stream(state_ptr: i64, next_fn: i64) -> AsyncStream {
    AsyncStream::new(state_ptr, next_fn)
}

# ============================================
# Memory helpers (extern)
# ============================================
X F malloc(size: i64) -> i64
X F free(ptr: i64) -> i64
X F store_i64(ptr: i64, value: i64) -> i64
X F load_i64(ptr: i64) -> i64
