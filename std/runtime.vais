# Async Runtime - Single-threaded task executor
# Provides spawn, block_on, and cooperative scheduling

# Task status constants
C TASK_PENDING: i64 = 0
C TASK_RUNNING: i64 = 1
C TASK_READY: i64 = 2
C TASK_COMPLETED: i64 = 3

# Maximum number of concurrent tasks
C MAX_TASKS: i64 = 256

# Task Node - represents a spawned async task
S TaskNode {
    id: i64,
    future_ptr: i64,    # Pointer to future state struct
    poll_fn: i64,       # Function pointer to poll function
    status: i64,
    result: i64,
    next: i64           # Pointer to next task (linked list)
}

X TaskNode {
    F new(id: i64, future_ptr: i64, poll_fn: i64) -> TaskNode {
        TaskNode {
            id: id,
            future_ptr: future_ptr,
            poll_fn: poll_fn,
            status: TASK_PENDING,
            result: 0,
            next: 0
        }
    }

    F is_completed(&self) -> i64 {
        self.status == TASK_COMPLETED
    }

    F is_pending(&self) -> i64 {
        self.status == TASK_PENDING
    }
}

# JoinHandle - returned when spawning a task
# Can be awaited to get the task's result
S JoinHandle {
    task_id: i64,
    task_ptr: i64       # Pointer to TaskNode
}

X JoinHandle {
    F new(task_id: i64, task_ptr: i64) -> JoinHandle {
        JoinHandle { task_id: task_id, task_ptr: task_ptr }
    }
}

# Runtime - the async task scheduler
S Runtime {
    task_count: i64,
    next_task_id: i64,
    head: i64,          # First task in queue
    tail: i64,          # Last task in queue
    current_task: i64   # Currently executing task
}

X Runtime {
    F new() -> Runtime {
        Runtime {
            task_count: 0,
            next_task_id: 0,
            head: 0,
            tail: 0,
            current_task: 0
        }
    }

    # Spawn a new task onto the runtime
    # Returns a JoinHandle for the spawned task
    F spawn(&self, future_ptr: i64, poll_fn: i64) -> JoinHandle {
        # Allocate new TaskNode
        task_ptr := malloc(48)  # Size of TaskNode

        task_id := self.next_task_id
        self.next_task_id = self.next_task_id + 1

        # Initialize task
        # Store fields directly to memory
        task_node_ptr := task_ptr

        # id
        store_i64(task_node_ptr, task_id)
        # future_ptr
        store_i64(task_node_ptr + 8, future_ptr)
        # poll_fn
        store_i64(task_node_ptr + 16, poll_fn)
        # status = TASK_PENDING
        store_i64(task_node_ptr + 24, TASK_PENDING)
        # result = 0
        store_i64(task_node_ptr + 32, 0)
        # next = 0
        store_i64(task_node_ptr + 40, 0)

        # Add to task queue
        L self.tail == 0 {
            # First task
            self.head = task_ptr
            self.tail = task_ptr
        } ! {
            # Append to tail
            store_i64(self.tail + 40, task_ptr)
            self.tail = task_ptr
        }

        self.task_count = self.task_count + 1

        JoinHandle::new(task_id, task_ptr)
    }

    # Run the scheduler until all tasks complete
    F run(&self) -> i64 {
        # Keep polling until no pending tasks
        L self.task_count > 0 {
            made_progress := 0

            # Iterate through task list
            current := self.head
            L current != 0 {
                status := load_i64(current + 24)

                L status == TASK_PENDING {
                    # Mark as running
                    store_i64(current + 24, TASK_RUNNING)

                    # Get future_ptr and poll_fn
                    future_ptr := load_i64(current + 8)
                    poll_fn := load_i64(current + 16)

                    # Call poll function - returns {status, result}
                    poll_result := call_poll(poll_fn, future_ptr)
                    poll_status := extract_poll_status(poll_result)
                    poll_value := extract_poll_value(poll_result)

                    L poll_status == 1 {
                        # Ready - task completed
                        store_i64(current + 24, TASK_COMPLETED)
                        store_i64(current + 32, poll_value)
                        self.task_count = self.task_count - 1
                        made_progress = 1
                    } ! {
                        # Still pending
                        store_i64(current + 24, TASK_PENDING)
                    }
                }

                # Move to next task
                current = load_i64(current + 40)
            }

            # If no progress made and tasks remain, we might be deadlocked
            # For now just continue (cooperative multitasking)
        }

        0
    }

    # Block on a single future until completion
    F block_on(&self, future_ptr: i64, poll_fn: i64) -> i64 {
        # Simple busy-poll loop
        L 1 {
            poll_result := call_poll(poll_fn, future_ptr)
            poll_status := extract_poll_status(poll_result)
            poll_value := extract_poll_value(poll_result)

            L poll_status == 1 {
                R poll_value
            }
            # Pending - continue polling
        }
        0
    }
}

# Global runtime instance
V __GLOBAL_RUNTIME: i64 = 0

# Initialize global runtime
F runtime_init() -> i64 {
    L __GLOBAL_RUNTIME == 0 {
        __GLOBAL_RUNTIME = malloc(40)  # Size of Runtime struct
        # Initialize all fields to 0
        store_i64(__GLOBAL_RUNTIME, 0)       # task_count
        store_i64(__GLOBAL_RUNTIME + 8, 0)   # next_task_id
        store_i64(__GLOBAL_RUNTIME + 16, 0)  # head
        store_i64(__GLOBAL_RUNTIME + 24, 0)  # tail
        store_i64(__GLOBAL_RUNTIME + 32, 0)  # current_task
    }
    __GLOBAL_RUNTIME
}

# Get global runtime
F get_runtime() -> i64 {
    L __GLOBAL_RUNTIME == 0 {
        runtime_init()
    }
    __GLOBAL_RUNTIME
}

# Spawn a task on the global runtime
F spawn(future_ptr: i64, poll_fn: i64) -> JoinHandle {
    rt := get_runtime()
    rt_ptr := rt as *Runtime
    rt_ptr.spawn(future_ptr, poll_fn)
}

# Block on a future using global runtime
F block_on(future_ptr: i64, poll_fn: i64) -> i64 {
    rt := get_runtime()
    rt_ptr := rt as *Runtime
    rt_ptr.block_on(future_ptr, poll_fn)
}

# Run all spawned tasks to completion
F run_all() -> i64 {
    rt := get_runtime()
    rt_ptr := rt as *Runtime
    rt_ptr.run()
}

# Memory helper functions (extern declarations)
X F malloc(size: i64) -> i64
X F free(ptr: i64) -> i64
X F store_i64(ptr: i64, value: i64) -> i64
X F load_i64(ptr: i64) -> i64
X F call_poll(poll_fn: i64, future_ptr: i64) -> i64
X F extract_poll_status(poll_result: i64) -> i64
X F extract_poll_value(poll_result: i64) -> i64

# Platform syscall externs (kqueue/kevent on macOS, epoll on Linux)
X F kqueue() -> i64
X F kevent_register(kq: i64, fd: i64, filter: i64, flags: i64) -> i64
X F kevent_wait(kq: i64, events_buf: i64, max_events: i64, timeout_ms: i64) -> i64
X F kevent_get_fd(events_buf: i64, index: i64) -> i64
X F kevent_get_filter(events_buf: i64, index: i64) -> i64
X F close(fd: i64) -> i64
X F pipe(fds_buf: i64) -> i64
X F write_byte(fd: i64, value: i64) -> i64
X F read_byte(fd: i64) -> i64
X F time_now_ms() -> i64

# ============================================
# Event Loop - kqueue/epoll based I/O reactor
# ============================================

# Event filter constants (matching kqueue EVFILT_*)
C EVFILT_READ: i64 = -1
C EVFILT_WRITE: i64 = -2
C EVFILT_TIMER: i64 = -7

# Event flags
C EV_ADD: i64 = 1
C EV_DELETE: i64 = 2
C EV_ONESHOT: i64 = 16

# Maximum events per kevent() call
C MAX_EVENTS: i64 = 64

# Waker token - special fd used to wake up the event loop
C WAKER_TOKEN: i64 = -999

# Event source types
C SOURCE_FD_READ: i64 = 1
C SOURCE_FD_WRITE: i64 = 2
C SOURCE_TIMER: i64 = 3

# EventSource - tracks what a task is waiting on
S EventSource {
    source_type: i64,   # SOURCE_FD_READ, SOURCE_FD_WRITE, SOURCE_TIMER
    fd: i64,            # File descriptor or timer ID
    task_ptr: i64,      # Pointer to the waiting TaskNode
    deadline_ms: i64,   # Deadline for timers (absolute time in ms)
    next: i64           # Linked list pointer
}

# EventLoop - the I/O reactor using kqueue
S EventLoop {
    kq: i64,                # kqueue file descriptor
    waker_read_fd: i64,     # Pipe read end (for waking up the loop)
    waker_write_fd: i64,    # Pipe write end
    sources_head: i64,      # Head of event source linked list
    sources_tail: i64,      # Tail of event source linked list
    source_count: i64,      # Number of registered event sources
    events_buf: i64,        # Buffer for kevent results
    running: i64            # 1 if event loop is active
}

X EventLoop {
    F new() -> EventLoop {
        # Create kqueue instance
        kq := kqueue()

        # Create wake-up pipe
        pipe_buf := malloc(16)  # Space for 2 i64 fds
        pipe(pipe_buf)
        read_fd := load_i64(pipe_buf)
        write_fd := load_i64(pipe_buf + 8)
        free(pipe_buf)

        # Register waker pipe with kqueue
        kevent_register(kq, read_fd, EVFILT_READ, EV_ADD)

        # Allocate events buffer (MAX_EVENTS * 16 bytes each: fd + filter)
        events_buf := malloc(MAX_EVENTS * 16)

        EventLoop {
            kq: kq,
            waker_read_fd: read_fd,
            waker_write_fd: write_fd,
            sources_head: 0,
            sources_tail: 0,
            source_count: 0,
            events_buf: events_buf,
            running: 0
        }
    }

    # Register interest in a file descriptor for reading
    F register_read(&self, fd: i64, task_ptr: i64) -> i64 {
        kevent_register(self.kq, fd, EVFILT_READ, EV_ADD)
        self.add_source(SOURCE_FD_READ, fd, task_ptr, 0)
    }

    # Register interest in a file descriptor for writing
    F register_write(&self, fd: i64, task_ptr: i64) -> i64 {
        kevent_register(self.kq, fd, EVFILT_WRITE, EV_ADD)
        self.add_source(SOURCE_FD_WRITE, fd, task_ptr, 0)
    }

    # Register a timer (deadline in milliseconds from now)
    F register_timer(&self, timer_id: i64, delay_ms: i64, task_ptr: i64) -> i64 {
        deadline := time_now_ms() + delay_ms
        kevent_register(self.kq, timer_id, EVFILT_TIMER, EV_ADD)
        self.add_source(SOURCE_TIMER, timer_id, task_ptr, deadline)
    }

    # Deregister an event source by fd
    F deregister(&self, fd: i64, filter: i64) -> i64 {
        kevent_register(self.kq, fd, filter, EV_DELETE)
        self.remove_source(fd)
    }

    # Add an event source to the linked list
    F add_source(&self, source_type: i64, fd: i64, task_ptr: i64, deadline_ms: i64) -> i64 {
        # Allocate EventSource (5 fields * 8 bytes = 40 bytes)
        src_ptr := malloc(40)
        store_i64(src_ptr, source_type)
        store_i64(src_ptr + 8, fd)
        store_i64(src_ptr + 16, task_ptr)
        store_i64(src_ptr + 24, deadline_ms)
        store_i64(src_ptr + 32, 0)  # next = null

        L self.sources_tail == 0 {
            self.sources_head = src_ptr
            self.sources_tail = src_ptr
        } ! {
            store_i64(self.sources_tail + 32, src_ptr)
            self.sources_tail = src_ptr
        }

        self.source_count = self.source_count + 1
        src_ptr
    }

    # Remove an event source by fd
    F remove_source(&self, fd: i64) -> i64 {
        prev := 0
        current := self.sources_head

        L current != 0 {
            src_fd := load_i64(current + 8)
            next := load_i64(current + 32)

            L src_fd == fd {
                # Unlink from list
                L prev == 0 {
                    self.sources_head = next
                } ! {
                    store_i64(prev + 32, next)
                }

                L next == 0 {
                    self.sources_tail = prev
                }

                free(current)
                self.source_count = self.source_count - 1
                R 1
            }

            prev = current
            current = next
        }
        0
    }

    # Find the task waiting on a given fd
    F find_task_for_fd(&self, fd: i64) -> i64 {
        current := self.sources_head
        L current != 0 {
            src_fd := load_i64(current + 8)
            L src_fd == fd {
                R load_i64(current + 16)  # task_ptr
            }
            current = load_i64(current + 32)
        }
        0
    }

    # Wake up the event loop from another context
    F wake(&self) -> i64 {
        write_byte(self.waker_write_fd, 1)
    }

    # Drain the waker pipe (consume wake-up signal)
    F drain_waker(&self) -> i64 {
        read_byte(self.waker_read_fd)
    }

    # Poll for I/O events with timeout
    # Returns number of ready events
    F poll_events(&self, timeout_ms: i64) -> i64 {
        kevent_wait(self.kq, self.events_buf, MAX_EVENTS, timeout_ms)
    }

    # Get fd from event at index
    F event_fd(&self, index: i64) -> i64 {
        kevent_get_fd(self.events_buf, index)
    }

    # Get filter from event at index
    F event_filter(&self, index: i64) -> i64 {
        kevent_get_filter(self.events_buf, index)
    }

    # Cleanup all resources
    F cleanup(&self) -> i64 {
        # Free all event sources
        current := self.sources_head
        L current != 0 {
            next := load_i64(current + 32)
            free(current)
            current = next
        }

        # Close kqueue fd
        close(self.kq)
        # Close waker pipe
        close(self.waker_read_fd)
        close(self.waker_write_fd)
        # Free events buffer
        free(self.events_buf)

        0
    }
}

# ============================================
# Reactor Runtime - combines executor + event loop
# ============================================

# ReactorRuntime - async executor with I/O event loop
S ReactorRuntime {
    task_count: i64,
    next_task_id: i64,
    head: i64,
    tail: i64,
    current_task: i64,
    event_loop: i64,       # Pointer to EventLoop
    next_timer_id: i64     # Counter for timer IDs
}

X ReactorRuntime {
    F new() -> ReactorRuntime {
        # Allocate EventLoop on heap (8 fields * 8 bytes = 64 bytes)
        el_ptr := malloc(64)

        # Create the event loop
        kq := kqueue()
        pipe_buf := malloc(16)
        pipe(pipe_buf)
        read_fd := load_i64(pipe_buf)
        write_fd := load_i64(pipe_buf + 8)
        free(pipe_buf)

        kevent_register(kq, read_fd, EVFILT_READ, EV_ADD)

        events_buf := malloc(MAX_EVENTS * 16)

        # Store EventLoop fields
        store_i64(el_ptr, kq)
        store_i64(el_ptr + 8, read_fd)
        store_i64(el_ptr + 16, write_fd)
        store_i64(el_ptr + 24, 0)  # sources_head
        store_i64(el_ptr + 32, 0)  # sources_tail
        store_i64(el_ptr + 40, 0)  # source_count
        store_i64(el_ptr + 48, events_buf)
        store_i64(el_ptr + 56, 0)  # running

        ReactorRuntime {
            task_count: 0,
            next_task_id: 0,
            head: 0,
            tail: 0,
            current_task: 0,
            event_loop: el_ptr,
            next_timer_id: 1000
        }
    }

    # Get the event loop pointer (for registering I/O)
    F get_event_loop(&self) -> i64 {
        self.event_loop
    }

    # Spawn a new task
    F spawn(&self, future_ptr: i64, poll_fn: i64) -> JoinHandle {
        task_ptr := malloc(48)
        task_id := self.next_task_id
        self.next_task_id = self.next_task_id + 1

        store_i64(task_ptr, task_id)
        store_i64(task_ptr + 8, future_ptr)
        store_i64(task_ptr + 16, poll_fn)
        store_i64(task_ptr + 24, TASK_PENDING)
        store_i64(task_ptr + 32, 0)
        store_i64(task_ptr + 40, 0)

        L self.tail == 0 {
            self.head = task_ptr
            self.tail = task_ptr
        } ! {
            store_i64(self.tail + 40, task_ptr)
            self.tail = task_ptr
        }

        self.task_count = self.task_count + 1
        JoinHandle::new(task_id, task_ptr)
    }

    # Register a read interest for the current task
    F wait_readable(&self, fd: i64) -> i64 {
        el := self.event_loop as *EventLoop
        el.register_read(fd, self.current_task)
    }

    # Register a write interest for the current task
    F wait_writable(&self, fd: i64) -> i64 {
        el := self.event_loop as *EventLoop
        el.register_write(fd, self.current_task)
    }

    # Sleep for delay_ms milliseconds (registers timer)
    F sleep_ms(&self, delay_ms: i64) -> i64 {
        el := self.event_loop as *EventLoop
        timer_id := self.next_timer_id
        self.next_timer_id = self.next_timer_id + 1
        el.register_timer(timer_id, delay_ms, self.current_task)
        timer_id
    }

    # Run all tasks to completion using event-driven scheduling
    F run(&self) -> i64 {
        el := self.event_loop as *EventLoop

        L self.task_count > 0 {
            # Phase 1: Poll all ready/pending tasks
            made_progress := 0
            current := self.head
            L current != 0 {
                status := load_i64(current + 24)

                L status == TASK_PENDING {
                    self.current_task = current
                    store_i64(current + 24, TASK_RUNNING)

                    future_ptr := load_i64(current + 8)
                    poll_fn := load_i64(current + 16)

                    poll_result := call_poll(poll_fn, future_ptr)
                    poll_status := extract_poll_status(poll_result)
                    poll_value := extract_poll_value(poll_result)

                    L poll_status == 1 {
                        store_i64(current + 24, TASK_COMPLETED)
                        store_i64(current + 32, poll_value)
                        self.task_count = self.task_count - 1
                        made_progress = 1
                    } ! {
                        # Task is waiting for I/O - mark as pending
                        store_i64(current + 24, TASK_PENDING)
                    }
                }

                L status == TASK_READY {
                    # Task was woken by an event - poll it
                    self.current_task = current
                    store_i64(current + 24, TASK_RUNNING)

                    future_ptr := load_i64(current + 8)
                    poll_fn := load_i64(current + 16)

                    poll_result := call_poll(poll_fn, future_ptr)
                    poll_status := extract_poll_status(poll_result)
                    poll_value := extract_poll_value(poll_result)

                    L poll_status == 1 {
                        store_i64(current + 24, TASK_COMPLETED)
                        store_i64(current + 32, poll_value)
                        self.task_count = self.task_count - 1
                        made_progress = 1
                    } ! {
                        store_i64(current + 24, TASK_PENDING)
                    }
                }

                current = load_i64(current + 40)
            }

            # Phase 2: If no progress, wait for I/O events
            L made_progress == 0 {
                # Calculate timeout: if we have pending tasks, use short timeout
                # Otherwise wait indefinitely (-1)
                timeout := 100  # 100ms default timeout

                n_events := el.poll_events(timeout)

                # Process events and wake corresponding tasks
                i := 0
                L i < n_events {
                    ev_fd := el.event_fd(i)

                    # Check if it's the waker pipe
                    L ev_fd == el.waker_read_fd {
                        el.drain_waker()
                    } ! {
                        # Find the task waiting on this fd and mark it ready
                        task_ptr := el.find_task_for_fd(ev_fd)
                        L task_ptr != 0 {
                            store_i64(task_ptr + 24, TASK_READY)
                        }
                    }

                    i = i + 1
                }
            }
        }

        # Cleanup
        el.cleanup()
        0
    }

    # Block on a single future until completion (event-driven)
    F block_on(&self, future_ptr: i64, poll_fn: i64) -> i64 {
        el := self.event_loop as *EventLoop

        # Allocate a temporary task node
        task_ptr := malloc(48)
        store_i64(task_ptr, 0)          # id
        store_i64(task_ptr + 8, future_ptr)
        store_i64(task_ptr + 16, poll_fn)
        store_i64(task_ptr + 24, TASK_PENDING)
        store_i64(task_ptr + 32, 0)
        store_i64(task_ptr + 40, 0)

        self.current_task = task_ptr

        result := 0
        done := 0

        L done == 0 {
            poll_result := call_poll(poll_fn, future_ptr)
            poll_status := extract_poll_status(poll_result)
            poll_value := extract_poll_value(poll_result)

            L poll_status == 1 {
                result = poll_value
                done = 1
            } ! {
                # Wait for events instead of busy-polling
                n_events := el.poll_events(100)

                i := 0
                L i < n_events {
                    ev_fd := el.event_fd(i)
                    L ev_fd == el.waker_read_fd {
                        el.drain_waker()
                    }
                    i = i + 1
                }
            }
        }

        free(task_ptr)
        el.cleanup()
        result
    }
}

# ============================================
# Global Reactor Runtime
# ============================================

V __GLOBAL_REACTOR: i64 = 0

# Initialize global reactor runtime
F reactor_init() -> i64 {
    L __GLOBAL_REACTOR == 0 {
        __GLOBAL_REACTOR = malloc(56)  # Size of ReactorRuntime struct (7 fields)

        # Create EventLoop on heap
        el_ptr := malloc(64)
        kq := kqueue()
        pipe_buf := malloc(16)
        pipe(pipe_buf)
        read_fd := load_i64(pipe_buf)
        write_fd := load_i64(pipe_buf + 8)
        free(pipe_buf)

        kevent_register(kq, read_fd, EVFILT_READ, EV_ADD)
        events_buf := malloc(MAX_EVENTS * 16)

        store_i64(el_ptr, kq)
        store_i64(el_ptr + 8, read_fd)
        store_i64(el_ptr + 16, write_fd)
        store_i64(el_ptr + 24, 0)
        store_i64(el_ptr + 32, 0)
        store_i64(el_ptr + 40, 0)
        store_i64(el_ptr + 48, events_buf)
        store_i64(el_ptr + 56, 0)

        # Initialize ReactorRuntime fields
        store_i64(__GLOBAL_REACTOR, 0)         # task_count
        store_i64(__GLOBAL_REACTOR + 8, 0)     # next_task_id
        store_i64(__GLOBAL_REACTOR + 16, 0)    # head
        store_i64(__GLOBAL_REACTOR + 24, 0)    # tail
        store_i64(__GLOBAL_REACTOR + 32, 0)    # current_task
        store_i64(__GLOBAL_REACTOR + 40, el_ptr)  # event_loop
        store_i64(__GLOBAL_REACTOR + 48, 1000) # next_timer_id
    }
    __GLOBAL_REACTOR
}

# Get global reactor runtime
F get_reactor() -> i64 {
    L __GLOBAL_REACTOR == 0 {
        reactor_init()
    }
    __GLOBAL_REACTOR
}

# Spawn a task on the reactor runtime
F reactor_spawn(future_ptr: i64, poll_fn: i64) -> JoinHandle {
    rt := get_reactor()
    rt_ptr := rt as *ReactorRuntime
    rt_ptr.spawn(future_ptr, poll_fn)
}

# Block on a future using the reactor runtime
F reactor_block_on(future_ptr: i64, poll_fn: i64) -> i64 {
    rt := get_reactor()
    rt_ptr := rt as *ReactorRuntime
    rt_ptr.block_on(future_ptr, poll_fn)
}

# Run all spawned tasks on the reactor
F reactor_run() -> i64 {
    rt := get_reactor()
    rt_ptr := rt as *ReactorRuntime
    rt_ptr.run()
}

# Wait for a file descriptor to become readable
F wait_readable(fd: i64) -> i64 {
    rt := get_reactor()
    rt_ptr := rt as *ReactorRuntime
    rt_ptr.wait_readable(fd)
}

# Wait for a file descriptor to become writable
F wait_writable(fd: i64) -> i64 {
    rt := get_reactor()
    rt_ptr := rt as *ReactorRuntime
    rt_ptr.wait_writable(fd)
}

# Sleep for the specified number of milliseconds
F sleep_ms(delay_ms: i64) -> i64 {
    rt := get_reactor()
    rt_ptr := rt as *ReactorRuntime
    rt_ptr.sleep_ms(delay_ms)
}

# ============================================
# Structured Concurrency - TaskGroup
# ============================================
# TaskGroup ensures all spawned child tasks complete (or are cancelled)
# before the group itself completes. This provides structured concurrency
# guarantees: no orphaned tasks, automatic cancellation on failure.

# Task entry in the group's task list
S TaskEntry {
    task_ptr: i64,      # Pointer to TaskNode
    future_ptr: i64,    # Pointer to future state
    poll_fn: i64,       # Poll function pointer
    status: i64,        # 0=pending, 1=running, 2=ready, 3=completed, 4=cancelled
    result: i64,        # Task result value
    error: i64,         # Error flag (0=ok, 1=error)
    next: i64           # Next entry pointer (linked list)
}

# TaskGroup - spawn and manage a group of concurrent tasks
# All tasks must complete before the group completes
S TaskGroup {
    name: i64,              # Pointer to name string (for debugging)
    head: i64,              # First task entry
    tail: i64,              # Last task entry
    task_count: i64,        # Total tasks spawned
    completed_count: i64,   # Tasks completed
    cancelled: i64,         # 1 if group was cancelled
    cancel_on_error: i64,   # 1 if siblings should be cancelled on error
    results: i64,           # Pointer to results array
    max_concurrency: i64    # Maximum concurrent tasks (0 = unlimited)
}

X TaskGroup {
    # Create a new TaskGroup
    F new() -> TaskGroup {
        TaskGroup {
            name: 0,
            head: 0,
            tail: 0,
            task_count: 0,
            completed_count: 0,
            cancelled: 0,
            cancel_on_error: 1,
            results: 0,
            max_concurrency: 0
        }
    }

    # Create a named TaskGroup (for debugging)
    F named(name_ptr: i64) -> TaskGroup {
        TaskGroup {
            name: name_ptr,
            head: 0,
            tail: 0,
            task_count: 0,
            completed_count: 0,
            cancelled: 0,
            cancel_on_error: 1,
            results: 0,
            max_concurrency: 0
        }
    }

    # Set whether to cancel all tasks when one fails
    F set_cancel_on_error(&self, enabled: i64) -> i64 {
        self.cancel_on_error = enabled
        0
    }

    # Set maximum concurrent tasks (0 = unlimited)
    F set_max_concurrency(&self, max: i64) -> i64 {
        self.max_concurrency = max
        0
    }

    # Spawn a new task into the group
    F spawn(&self, future_ptr: i64, poll_fn: i64) -> i64 {
        L self.cancelled == 1 {
            R 0  # Don't spawn if group is cancelled
        }

        # Allocate TaskEntry (7 fields * 8 bytes = 56 bytes)
        entry_ptr := malloc(56)

        # Initialize entry
        store_i64(entry_ptr, 0)              # task_ptr (unused for now)
        store_i64(entry_ptr + 8, future_ptr) # future_ptr
        store_i64(entry_ptr + 16, poll_fn)   # poll_fn
        store_i64(entry_ptr + 24, 0)         # status = pending
        store_i64(entry_ptr + 32, 0)         # result
        store_i64(entry_ptr + 40, 0)         # error
        store_i64(entry_ptr + 48, 0)         # next

        # Add to linked list
        L self.tail == 0 {
            self.head = entry_ptr
            self.tail = entry_ptr
        } ! {
            store_i64(self.tail + 48, entry_ptr)
            self.tail = entry_ptr
        }

        self.task_count = self.task_count + 1
        self.task_count  # Return task index
    }

    # Run all tasks in the group to completion
    # Returns 0 on success, 1 if any task failed
    F run(&self) -> i64 {
        has_error := 0

        L self.completed_count < self.task_count {
            L self.cancelled == 1 {
                # Cancel remaining tasks
                self.cancel_remaining()
                R 1
            }

            # Poll all pending/running tasks
            current := self.head
            L current != 0 {
                status := load_i64(current + 24)

                # Only poll pending or running tasks
                L status < 2 {
                    future_ptr := load_i64(current + 8)
                    poll_fn := load_i64(current + 16)

                    # Mark as running
                    store_i64(current + 24, 1)

                    # Poll the task
                    poll_result := call_poll(poll_fn, future_ptr)
                    poll_status := extract_poll_status(poll_result)
                    poll_value := extract_poll_value(poll_result)

                    L poll_status == 1 {
                        # Task completed
                        store_i64(current + 24, 3)  # COMPLETED
                        store_i64(current + 32, poll_value)
                        self.completed_count = self.completed_count + 1

                        # Check if result indicates an error (negative = error)
                        L poll_value < 0 {
                            store_i64(current + 40, 1)  # error flag
                            has_error = 1

                            L self.cancel_on_error == 1 {
                                self.cancelled = 1
                            }
                        }
                    } ! {
                        # Still pending
                        store_i64(current + 24, 0)
                    }
                }

                current = load_i64(current + 48)
            }
        }

        has_error
    }

    # Cancel all remaining tasks
    F cancel_remaining(&self) -> i64 {
        current := self.head
        L current != 0 {
            status := load_i64(current + 24)
            # Cancel tasks that haven't completed
            L status < 3 {
                store_i64(current + 24, 4)  # CANCELLED
                self.completed_count = self.completed_count + 1
            }
            current = load_i64(current + 48)
        }
        0
    }

    # Cancel the entire group
    F cancel(&self) -> i64 {
        self.cancelled = 1
        self.cancel_remaining()
    }

    # Get the number of completed tasks
    F completed(&self) -> i64 {
        self.completed_count
    }

    # Get the total number of tasks
    F total(&self) -> i64 {
        self.task_count
    }

    # Check if all tasks are done
    F is_done(&self) -> i64 {
        self.completed_count == self.task_count
    }

    # Check if group was cancelled
    F is_cancelled(&self) -> i64 {
        self.cancelled
    }

    # Get result of task at index (0-based)
    F result(&self, index: i64) -> i64 {
        current := self.head
        i := 0
        L current != 0 {
            L i == index {
                R load_i64(current + 32)
            }
            i = i + 1
            current = load_i64(current + 48)
        }
        0
    }

    # Get error flag of task at index
    F has_error(&self, index: i64) -> i64 {
        current := self.head
        i := 0
        L current != 0 {
            L i == index {
                R load_i64(current + 40)
            }
            i = i + 1
            current = load_i64(current + 48)
        }
        0
    }

    # Get status of task at index
    F task_status(&self, index: i64) -> i64 {
        current := self.head
        i := 0
        L current != 0 {
            L i == index {
                R load_i64(current + 24)
            }
            i = i + 1
            current = load_i64(current + 48)
        }
        0
    }

    # Free all task entries
    F cleanup(&self) -> i64 {
        current := self.head
        L current != 0 {
            next := load_i64(current + 48)
            free(current)
            current = next
        }
        self.head = 0
        self.tail = 0
        0
    }
}

# ============================================
# Scoped Task - ensures tasks complete within scope
# ============================================

# ScopedTask runs a TaskGroup and guarantees cleanup
S ScopedTask {
    group: i64      # Pointer to TaskGroup
}

X ScopedTask {
    F new() -> ScopedTask {
        # Allocate TaskGroup on heap
        group_ptr := malloc(72)  # 9 fields * 8 bytes
        # Initialize all fields to 0
        i := 0
        L i < 9 {
            store_i64(group_ptr + i * 8, 0)
            i = i + 1
        }
        # Set cancel_on_error default to 1
        store_i64(group_ptr + 48, 1)

        ScopedTask { group: group_ptr }
    }

    F spawn(&self, future_ptr: i64, poll_fn: i64) -> i64 {
        group_ptr := self.group as *TaskGroup
        group_ptr.spawn(future_ptr, poll_fn)
    }

    # Run all tasks and cleanup - guaranteed to not leak tasks
    F run_and_cleanup(&self) -> i64 {
        group_ptr := self.group as *TaskGroup
        result := group_ptr.run()

        # Always cleanup, even on error
        group_ptr.cleanup()

        result
    }
}

# ============================================
# Helper functions for structured concurrency
# ============================================

# Create a new task group
F task_group() -> TaskGroup {
    TaskGroup::new()
}

# Create a named task group
F task_group_named(name_ptr: i64) -> TaskGroup {
    TaskGroup::named(name_ptr)
}

# Create a scoped task runner
F scoped_task() -> ScopedTask {
    ScopedTask::new()
}

# ============================================
# Select - wait for first of N futures
# ============================================
# select takes up to 4 future/poll pairs and returns
# the index (0-based) and result of the first one to complete.

# SelectResult holds which future completed and its value
S SelectResult {
    index: i64,     # Which future completed (0-based)
    value: i64      # Result value
}

X SelectResult {
    F new(index: i64, value: i64) -> SelectResult {
        SelectResult { index: index, value: value }
    }
}

# select2: wait for the first of 2 futures to complete
F select2(fp1: i64, pf1: i64, fp2: i64, pf2: i64) -> SelectResult {
    L 1 {
        # Poll future 1
        r1 := call_poll(pf1, fp1)
        s1 := extract_poll_status(r1)
        v1 := extract_poll_value(r1)
        I s1 == 1 { R SelectResult::new(0, v1) }

        # Poll future 2
        r2 := call_poll(pf2, fp2)
        s2 := extract_poll_status(r2)
        v2 := extract_poll_value(r2)
        I s2 == 1 { R SelectResult::new(1, v2) }
    }
    SelectResult::new(-1, 0)
}

# select3: wait for the first of 3 futures to complete
F select3(fp1: i64, pf1: i64, fp2: i64, pf2: i64, fp3: i64, pf3: i64) -> SelectResult {
    L 1 {
        r1 := call_poll(pf1, fp1)
        s1 := extract_poll_status(r1)
        v1 := extract_poll_value(r1)
        I s1 == 1 { R SelectResult::new(0, v1) }

        r2 := call_poll(pf2, fp2)
        s2 := extract_poll_status(r2)
        v2 := extract_poll_value(r2)
        I s2 == 1 { R SelectResult::new(1, v2) }

        r3 := call_poll(pf3, fp3)
        s3 := extract_poll_status(r3)
        v3 := extract_poll_value(r3)
        I s3 == 1 { R SelectResult::new(2, v3) }
    }
    SelectResult::new(-1, 0)
}

# select4: wait for the first of 4 futures to complete
F select4(fp1: i64, pf1: i64, fp2: i64, pf2: i64, fp3: i64, pf3: i64, fp4: i64, pf4: i64) -> SelectResult {
    L 1 {
        r1 := call_poll(pf1, fp1)
        s1 := extract_poll_status(r1)
        v1 := extract_poll_value(r1)
        I s1 == 1 { R SelectResult::new(0, v1) }

        r2 := call_poll(pf2, fp2)
        s2 := extract_poll_status(r2)
        v2 := extract_poll_value(r2)
        I s2 == 1 { R SelectResult::new(1, v2) }

        r3 := call_poll(pf3, fp3)
        s3 := extract_poll_status(r3)
        v3 := extract_poll_value(r3)
        I s3 == 1 { R SelectResult::new(2, v3) }

        r4 := call_poll(pf4, fp4)
        s4 := extract_poll_status(r4)
        v4 := extract_poll_value(r4)
        I s4 == 1 { R SelectResult::new(3, v4) }
    }
    SelectResult::new(-1, 0)
}

# ============================================
# Join - wait for all N futures to complete
# ============================================
# join waits for all futures to complete and returns
# the results in an allocated array.

# JoinResult holds results of all completed futures
S JoinResult {
    results_ptr: i64,   # Pointer to i64 array of results
    count: i64          # Number of results
}

X JoinResult {
    F new(results_ptr: i64, count: i64) -> JoinResult {
        JoinResult { results_ptr: results_ptr, count: count }
    }

    # Get result at index
    F get(&self, index: i64) -> i64 {
        I index >= 0 {
            I index < self.count {
                R load_i64(self.results_ptr + index * 8)
            }
        }
        0
    }

    # Free the results array
    F cleanup(&self) -> i64 {
        I self.results_ptr != 0 {
            free(self.results_ptr)
        }
        0
    }
}

# join2: wait for both futures to complete
F join2(fp1: i64, pf1: i64, fp2: i64, pf2: i64) -> JoinResult {
    results := malloc(16)  # 2 * 8 bytes
    done1 := mut 0
    done2 := mut 0
    v1 := mut 0
    v2 := mut 0

    L done1 == 0 {
        L done2 == 0 {
            I done1 == 0 {
                r1 := call_poll(pf1, fp1)
                s1 := extract_poll_status(r1)
                I s1 == 1 {
                    v1 = extract_poll_value(r1)
                    done1 = 1
                }
            }

            I done2 == 0 {
                r2 := call_poll(pf2, fp2)
                s2 := extract_poll_status(r2)
                I s2 == 1 {
                    v2 = extract_poll_value(r2)
                    done2 = 1
                }
            }

            I done1 == 1 {
                I done2 == 1 { B }
            }
        }
    }

    store_i64(results, v1)
    store_i64(results + 8, v2)
    JoinResult::new(results, 2)
}

# join3: wait for all 3 futures to complete
F join3(fp1: i64, pf1: i64, fp2: i64, pf2: i64, fp3: i64, pf3: i64) -> JoinResult {
    results := malloc(24)  # 3 * 8 bytes
    done1 := mut 0
    done2 := mut 0
    done3 := mut 0
    v1 := mut 0
    v2 := mut 0
    v3 := mut 0

    L 1 {
        I done1 == 0 {
            r1 := call_poll(pf1, fp1)
            s1 := extract_poll_status(r1)
            I s1 == 1 { v1 = extract_poll_value(r1); done1 = 1 }
        }
        I done2 == 0 {
            r2 := call_poll(pf2, fp2)
            s2 := extract_poll_status(r2)
            I s2 == 1 { v2 = extract_poll_value(r2); done2 = 1 }
        }
        I done3 == 0 {
            r3 := call_poll(pf3, fp3)
            s3 := extract_poll_status(r3)
            I s3 == 1 { v3 = extract_poll_value(r3); done3 = 1 }
        }

        I done1 == 1 { I done2 == 1 { I done3 == 1 { B } } }
    }

    store_i64(results, v1)
    store_i64(results + 8, v2)
    store_i64(results + 16, v3)
    JoinResult::new(results, 3)
}

# ============================================
# Waker - callback-based wake mechanism
# ============================================
# Waker allows a future to register a callback that
# will be called when the future should be re-polled.

S Waker {
    wake_fn: i64,       # Function pointer to wake callback
    task_ptr: i64,      # Pointer to the task to wake
    runtime_ptr: i64    # Pointer to the runtime
}

X Waker {
    F new(wake_fn: i64, task_ptr: i64, runtime_ptr: i64) -> Waker {
        Waker {
            wake_fn: wake_fn,
            task_ptr: task_ptr,
            runtime_ptr: runtime_ptr
        }
    }

    # Wake the associated task (mark as TASK_READY)
    F wake(&self) -> i64 {
        I self.task_ptr != 0 {
            # Set task status to TASK_READY
            store_i64(self.task_ptr + 24, TASK_READY)
        }
        0
    }

    # Wake by reference (non-consuming)
    F wake_by_ref(&self) -> i64 {
        self.wake()
    }
}

# Create a waker for the current task in the reactor
F create_waker() -> Waker {
    rt := get_reactor()
    current := load_i64(rt + 32)  # current_task field
    Waker::new(0, current, rt)
}

# ============================================
# Timeout helper - wraps a future with deadline
# ============================================

S Timeout {
    inner_fp: i64,      # Inner future pointer
    inner_pf: i64,      # Inner poll function
    deadline_ms: i64,   # Absolute deadline (ms since epoch)
    started: i64        # Whether we've started the timer
}

X Timeout {
    F new(inner_fp: i64, inner_pf: i64, timeout_ms: i64) -> Timeout {
        Timeout {
            inner_fp: inner_fp,
            inner_pf: inner_pf,
            deadline_ms: time_now_ms() + timeout_ms,
            started: 0
        }
    }

    # Poll: returns inner result if ready, -1 if timeout
    F poll(&self) -> i64 {
        # Check timeout
        now := time_now_ms()
        I now >= self.deadline_ms {
            R -1  # Timeout
        }

        # Poll inner future
        r := call_poll(self.inner_pf, self.inner_fp)
        s := extract_poll_status(r)
        v := extract_poll_value(r)

        I s == 1 {
            R v  # Ready
        }

        0  # Pending (encoded as 0, caller must check status)
    }
}

# Create a timeout wrapper
F with_timeout(inner_fp: i64, inner_pf: i64, timeout_ms: i64) -> Timeout {
    Timeout::new(inner_fp, inner_pf, timeout_ms)
}
