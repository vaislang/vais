#!/usr/bin/env python3
"""
Vais Parser í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ì˜ˆì œ íŒŒì¼ë“¤ì„ íŒŒì‹±í•˜ê³  ê²€ì¦ ê²°ê³¼ë¥¼ ì¶œë ¥
"""

import sys
import os
from pathlib import Path

# í˜„ìž¬ ë””ë ‰í† ë¦¬ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from lexer import tokenize, TokenType
from parser import parse, ParseError
from validator import validate, ErrorSeverity
from ast_nodes import ASTPrinter


def test_lexer(source: str, name: str):
    """ë ‰ì„œ í…ŒìŠ¤íŠ¸"""
    print(f"\n{'='*60}")
    print(f"ðŸ”¤ Lexer Test: {name}")
    print('='*60)

    tokens = tokenize(source)
    non_newline = [t for t in tokens if t.type != TokenType.NEWLINE]

    print(f"Total tokens: {len(tokens)} (non-newline: {len(non_newline)})")
    print(f"First 20 tokens:")
    for i, token in enumerate(non_newline[:20]):
        print(f"  {i+1:3}. {token}")
    if len(non_newline) > 20:
        print(f"  ... and {len(non_newline) - 20} more")

    return tokens


def test_parser(source: str, name: str):
    """íŒŒì„œ í…ŒìŠ¤íŠ¸"""
    print(f"\n{'='*60}")
    print(f"ðŸŒ³ Parser Test: {name}")
    print('='*60)

    try:
        ast = parse(source)
        print(f"âœ… íŒŒì‹± ì„±ê³µ!")
        print(f"\nðŸ“‹ AST ìš”ì•½:")
        print(f"  UNIT: {ast.unit.unit_type.value} {ast.unit.unit_id.full_name} {ast.unit.version or ''}")
        print(f"  META: {len(ast.meta.entries)} entries")
        for entry in ast.meta.entries:
            print(f"    - {entry.key}: {entry.value}")
        print(f"  INPUT: {len(ast.input.entries)} fields")
        for entry in ast.input.entries:
            print(f"    - {entry.name}: {entry.type_node}")
        print(f"  OUTPUT: {len(ast.output.entries)} fields")
        for entry in ast.output.entries:
            print(f"    - {entry.name}: {entry.type_node}")
        print(f"  INTENT: GOAL {ast.intent.goal_type.value}")
        if ast.intent.priorities:
            print(f"    PRIORITY: {' > '.join(p.value for p in ast.intent.priorities)}")
        print(f"  CONSTRAINT: {len(ast.constraint.constraints)} constraints")
        print(f"  FLOW: {len(ast.flow.nodes)} nodes, {len(ast.flow.edges)} edges")
        for node in ast.flow.nodes:
            params_str = ", ".join(f"{p.name}=..." for p in node.params)
            print(f"    - NODE {node.node_id}: {node.op_type.value}({params_str})")
        print(f"  EXECUTION: parallel={ast.execution.parallel}, target={ast.execution.target.value}")
        print(f"  VERIFY: {len(ast.verify.entries)} entries")

        return ast
    except ParseError as e:
        print(f"âŒ íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None


def test_validator(ast, name: str):
    """ê²€ì¦ê¸° í…ŒìŠ¤íŠ¸"""
    print(f"\n{'='*60}")
    print(f"âœ“ Validator Test: {name}")
    print('='*60)

    if not ast:
        print("âŒ ASTê°€ ì—†ì–´ ê²€ì¦ ìŠ¤í‚µ")
        return

    errors = validate(ast)

    error_count = sum(1 for e in errors if e.severity == ErrorSeverity.ERROR)
    warning_count = sum(1 for e in errors if e.severity == ErrorSeverity.WARNING)
    info_count = sum(1 for e in errors if e.severity == ErrorSeverity.INFO)

    if errors:
        print(f"ê²€ì¦ ê²°ê³¼: {error_count} errors, {warning_count} warnings, {info_count} info")
        for error in errors:
            icon = "âŒ" if error.severity == ErrorSeverity.ERROR else "âš ï¸" if error.severity == ErrorSeverity.WARNING else "â„¹ï¸"
            print(f"  {icon} {error}")
    else:
        print("âœ… ê²€ì¦ í†µê³¼! ì´ìŠˆ ì—†ìŒ")

    return errors


def test_file(filepath: str):
    """íŒŒì¼ í…ŒìŠ¤íŠ¸"""
    name = Path(filepath).name
    print(f"\n{'#'*70}")
    print(f"# Testing: {name}")
    print('#'*70)

    try:
        with open(filepath, 'r') as f:
            source = f.read()

        # test_lexer(source, name)  # í† í° ì¶œë ¥ì€ ë„ˆë¬´ ê¸¸ì–´ì„œ ìŠ¤í‚µ
        ast = test_parser(source, name)
        test_validator(ast, name)

        return ast is not None

    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {filepath}")
        return False
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("="*70)
    print("ðŸš€ Vais Parser Prototype Test Suite")
    print("="*70)

    # ì˜ˆì œ ë””ë ‰í† ë¦¬ ì°¾ê¸°
    script_dir = Path(__file__).parent
    examples_dir = script_dir.parent / "examples"

    if not examples_dir.exists():
        print(f"âŒ ì˜ˆì œ ë””ë ‰í† ë¦¬ ì—†ìŒ: {examples_dir}")
        return

    # ëª¨ë“  .vais íŒŒì¼ í…ŒìŠ¤íŠ¸
    vais_files = sorted(examples_dir.glob("*.vais"))

    if not vais_files:
        print(f"âŒ .vais íŒŒì¼ ì—†ìŒ: {examples_dir}")
        return

    print(f"\nðŸ“ ë°œê²¬ëœ ì˜ˆì œ íŒŒì¼: {len(vais_files)}ê°œ")
    for f in vais_files:
        print(f"  - {f.name}")

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = {}
    for filepath in vais_files:
        success = test_file(str(filepath))
        results[filepath.name] = success

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*70)
    print("ðŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*70)

    passed = sum(1 for v in results.values() if v)
    failed = len(results) - passed

    for name, success in results.items():
        icon = "âœ…" if success else "âŒ"
        print(f"  {icon} {name}")

    print(f"\nì´ {len(results)}ê°œ ì¤‘ {passed}ê°œ ì„±ê³µ, {failed}ê°œ ì‹¤íŒ¨")

    if failed > 0:
        sys.exit(1)


if __name__ == "__main__":
    main()
